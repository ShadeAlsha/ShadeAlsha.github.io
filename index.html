<!DOCTYPE HTML>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y5JHGS5GJZ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-Y5JHGS5GJZ');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Shaden A.">
    <title>Shaden Alshammari</title>
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" href="stylesheet.css">
</head>

<body>
    <table style="width:100%; max-width:900px; margin:auto; border-collapse:separate; border-spacing:0;">
        <tbody>
            <tr>
                <td style="width:63%; padding:2.5%; vertical-align:top;">
                    <h1 style="text-align: center;">Shaden Alshammari</h1>
                    <p>
                        Iâ€™m a graduate student in Computer Science and Engineering at 
                        <a href="https://csail.mit.edu/" style="color:#9c0b0b;">MIT CSAIL</a>, advised by 
                        <a href="https://billf.mit.edu/" style="color:#007ACC;">William T. Freeman</a>. My research focuses on advancing 
                        self-supervised learning, vision-language models, and imbalanced learning to enhance the understanding and 
                        generation of meaningful representations.
                    </p>
                    <p>
                        I completed my B.S. in Mathematics and Computer Science at MIT, where I worked with amazing mentors including 
                        <a href="https://www.ri.cmu.edu/ri-faculty/deva-ramanan/">Deva Ramanan</a> and 
                        <a href="https://scholar.google.com/citations?user=gDiWvFoAAAAJ">Shu Kong</a> at 
                        <a href="https://labs.ri.cmu.edu/av-center/" style="color:#9c0b0b;">CMU's Argo AI Center</a>, 
                        as well as <a href="http://www.cs.cmu.edu/~abhinavg/">Abhinav Gupta</a> and 
                        <a href="https://vdean.github.io">Victoria Dean</a> at 
                        <a href="https://www.ri.cmu.edu/" style="color:#9c0b0b;">CMUâ€™s Robotics Institute</a>.
                    </p>
                    <p>
                        Beyond research, Iâ€™m active in the math olympiad community as a former contestant (IMO Bronze 2017, EGMO and BMO Gold 2016). I also train students, design problems, and I served as a deputy leader and observer at IMO and EGMO.
                    </p>
                    <p style="text-align: center;">
                        <a href="mailto:shaden@mit.edu">Email</a> &nbsp;/&nbsp;
                        <a href="data/Shaden_CV_.pdf">CV</a> &nbsp;/&nbsp;
                        <a href="https://scholar.google.com/citations?user=2GYNli8AAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                        <a href="https://github.com/ShadeAlsha">GitHub</a>
                    </p>
                </td>
                <td style="width:37%; padding:2.5%; vertical-align:top;">
                    <img src="images/shaden.jpg" alt="Profile photo" style="width:100%; object-fit:cover; border-radius:50%;">
                </td>
            </tr>
        </tbody>
    </table>

    <!-- Research Section -->
    <div style="width:100%; max-width:900px; margin:auto;">
        <h2 style="text-align:left; margin-top:40px;">Research</h2>
        <table style="width:100%; margin:auto; border-spacing:0;">
            <tbody>
            <tr style="background-color:#fff8e0; border-radius:10px;">
                <td style="padding:10px; width:30%;">
                    <img src="images/I-Con2.png" alt="Unifying Framework" style="width:300px;">
                </td>
                <td style="padding:10px; width:70%;">
                    <a href="https://aka.ms/i-con">
                        <span class="papertitle">I-Con: A Unifying Framework for Representation Learning</span>
                    </a>
                    <br>
                    <strong>Shaden A.</strong>, John R. Hershey, Axel Feldmann, William T. Freeman, Mark Hamilton
                    <br>
                    <p>
                        ðŸ”— 
                        <a href="https://aka.ms/i-con" target="_blank">Project Website</a> | 
                        <a href="https://youtu.be/UvjTbnFzRac" target="_blank">Video Explainer</a> | 
                        <a href="https://news.mit.edu/2025/machine-learning-periodic-table-could-fuel-ai-discovery-0423" target="_blank">MIT News</a> |
                        <a href="https://arxiv.org/pdf/2504.16929?" target="_blank">Paper</a> | 
                        <a href="https://github.com/ShadeAlsha/ICon" target="_blank">Code</a> | <span style="color:red; font-weight:bold;">ICLR 2025 ðŸŽ‰</span>
                    </p>
                    <p>A unified framework that generalizes loss functions in representation learning, exposing connections across methods and achieving state-of-the-art results in unsupervised image classification on ImageNet-1K.</p>
                </td>
            </tr>
            <tr>
                <td style="padding:10px; width:30%;">
                    <img src="images/VisionLanguageModels.png" alt="Vision Language Models" style="width:300px;">
                </td>
                <td style="padding:10px; width:70%;">
                    <a>
                        <span class="papertitle">Vision-Language Models Do Not Understand Negation</span>
                    </a>
                    <br>
                    Kumail Alhamoud, <strong>Shaden A.</strong>, Yonglong Tian, Guohao Li, Philip Torr, Yoon Kim, Marzyeh Ghassemi
                    <br>
                    <p>
                        ðŸ”— 
                        <a href="http://negbench.github.io" target="_blank">Project Website</a> | 
                        <a href="https://youtu.be/oOJxwlKUE8M" target="_blank">Video Explainer</a> | 
                        <a href="https://news.mit.edu/2025/study-shows-vision-language-models-cant-handle-negation-words-queries-0514" target="_blank">MIT News</a> |
                        <a href="https://arxiv.org/pdf/2501.09425" target="_blank">Paper</a> | 
                        <a href="https://github.com/m1k2zoo/negbench" target="_blank">Code</a> | <span style="font-weight:bold;">CVPR 2025 </span>
                    </p>
                    <p>A benchmark evaluating negation understanding in vision-language models reveals performance limitations, with targeted improvements increasing recall by 10% and accuracy by 40%.</p>
                </td>                                
            </tr>
            <tr style="background-color:#fff8e0; border-radius:10px;">
                <td style="padding:20px; width:30%;">
                    <img src="images/ltr-wb2.png" alt="Long-tailed Recognition" style="width:100%; max-width:300px; border-radius:10px;">
                </td>
                <td style="padding:20px; width:70%; vertical-align:top;">
                    <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.pdf" style="text-decoration:none;">
                        <span class="papertitle" style="font-size:1.2em; font-weight:bold; color:#8730cf;">Long-tailed Recognition via Weight Balancing</span>
                    </a>
                    <br>
                    <strong>Shaden A.</strong>, Yu-Xiong Wang, Deva Ramanan, Shu Kong
                    <br>
                    <em><span style="color:black; font-weight:bold;">CVPR 2022</span></em> &nbsp; <span style="color:red; font-weight:bold;">(190 citations to date!)</span>
                    <p>This study explores weight balancing techniques like L2-normalization, weight decay, and MaxNorm to address bias in long-tailed recognition, achieving state-of-the-art results across five benchmarks by balancing classifier weights for rare and common classes.</p>
                </td>
            </tr>
            <tr style="background-color:#fff8e0; border-radius:10px;">
                <td style="padding:20px; width:30%;">
                    <img src="images/hearning-touch.png" alt="Contact Microphones" style="width:300px;">
                </td>
                <td style="padding:20px; width:70%;">
                    <a href="https://neurips.cc/virtual/2022/57568">
                        <span class="papertitle">Using Contact Microphones for Robot Manipulation</span>
                    </a>
                    <br>
                    <strong>Shaden A.</strong>, Victoria Dean, Tess Hellebrekers, Pedro Morgado, Abhinav Gupta
                    <br>
                    <em>Women in Computer Vision Workshop @ NeurIPS</em>, 2022
                    <br>
                    <p>This work combines visual data with contact audio to enhance manipulation in contact-rich tasks, leveraging high-frequency tactile signals from microphones to outperform single-modality approaches.</p>
                </td>
            </tr>
            <tr>
                <td style="padding:20px; width:30%;">
                    <img src="images/continual-ltr.png" alt="Continual Long-Tailed Recognition" style="width:300px;">
                </td>
                <td style="padding:20px; width:70%;">
                    <a href="https://drive.google.com/file/d/1RHc1cEMbl6MdgKOZBa-VM4UG_eHEO9y1/view?usp=sharing">
                        <span class="papertitle">Continual Long-Tailed Recognition: Merge Tail Classes Today, Separate them Tomorrow</span>
                    </a>
                    <br>
                    Yanan Li, <strong>Shaden A.</strong>, Bin Liu, Shu Kong
                    <br>
                    <em>Preprint</em>, 2022
                    <p>This work introduces a continual learning approach for long-tailed recognition, using a Mean-Shift module and Supervised Contrastive loss to improve feature learning and expedite finetuning across time periods, achieving state-of-the-art performance.</p>
                </td>
            </tr>
        </tbody>
    </table>

    <!-- Teaching Section -->
    <div style="width:100%; max-width:900px; margin:auto;">
        <h2 style="text-align:left; margin-top:40px;">Teaching</h2>
        <table style="width:100%; margin:auto; border-spacing:0;">
            <tbody>
            <tr>
                <td style="padding:10px; width:30%;">
                    <img src="images/math.png" alt="MIT Mathematics" style="width:200px;">
                </td>
                <td style="padding:10px; width:70%;">
                    <strong>Lead Graduate Instructor, Linear Algebra and Optimization (18.C06)</strong><br>
                    <a href="https://math.mit.edu/" style="color:#007ACC;">MIT Department of Mathematics</a> - Sep 2022 - Present
                    <p>I teach two weekly recitation sessions to help clarify challenging topics for 38 students and develop weekly handouts and problem sets for a larger group of 180 students.
                         I also coordinate a team of five TAs and three Graders. I was honored to be nominated by my students for the Teaching Awards.</p>
                </td>                                                     
            </tr>
            <tr>
                <td style="padding:10px; width:30%;">
                    <img src="images/ml_course.png" alt="MIT EECS" style="width:200px;">
                </td>
                <td style="padding:10px; width:70%;">
                    <strong>Teaching Assistant, Introduction to Machine Learning (6.036)</strong><br>
                    <a href="https://eecs.mit.edu/" style="color:#007ACC;">MIT EECS Department</a> - Jan 2024 - May 2024
                    <p>Supported professors in organizing technical materials on ML topics, conducted weekly recitations, lab sessions, and hosted office hours for student learning support.</p>
                </td>
            </tr>
            <tr>
                <td style="padding:10px; width:30%;">
                    <img src="images/imo.png" alt="Math Olympiad" style="width:200px;">
                </td>
                <td style="padding:10px; width:70%;">
                    <strong>Math Olympiad Trainer</strong><br>
                    + Deputy Leader and Observer @ IMO & EGMO (2019â€“2023)
                    <p>Trained students in combinatorics, number theory, algebra, and geometry for the International Math Olympiad (IMO), focusing on advanced problem-solving skills. Additionally, contributed by suggesting problems for exams for team selection tests.</p>
                </td>
            </tr>
        </tbody>
    </table>
    <p style="text-align:right; font-size:small;">
        Website design credits to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
    </p>
   </body>
</html>
