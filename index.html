<!DOCTYPE HTML>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-Y5JHGS5GJZ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-Y5JHGS5GJZ');
    </script>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Shaden A.">
    <title>Shaden Alshammari</title>
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f8f9fa;
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        .main-card {
            background: white;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.08);
            border-left: 4px solid #6c757d;
            margin-bottom: 30px;
            overflow: hidden;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        .main-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.12);
        }

        .hero-section {
            display: grid;
            grid-template-columns: 2fr 1fr;
            gap: 40px;
            padding: 40px;
            align-items: center;
        }

        .hero-content h1 {
            font-size: 3rem;
            font-weight: 700;
            color: #2c3e50;
            margin-bottom: 20px;
            animation: fadeInUp 1s ease-out;
        }

        .hero-content p {
            font-size: 1.1rem;
            margin-bottom: 20px;
            color: #555;
            animation: fadeInUp 1s ease-out 0.2s both;
        }

        .hero-links {
            display: flex;
            gap: 15px;
            margin-top: 30px;
            animation: fadeInUp 1s ease-out 0.4s both;
        }

        .hero-links a {
            padding: 10px 20px;
            background: #6c757d;
            color: white;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: all 0.2s ease;
            font-size: 0.9rem;
        }

        .hero-links a:hover {
            background: #5a6268;
            transform: translateY(-1px);
        }

        .profile-image {
            position: relative;
            animation: fadeInUp 1s ease-out 0.6s both;
        }

        .profile-image img {
            width: 100%;
            max-width: 280px;
            border-radius: 12px;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease;
        }

        .profile-image:hover img {
            transform: scale(1.02);
        }

        .section {
            background: white;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.08);
            border-left: 4px solid #6c757d;
            margin-bottom: 30px;
            padding: 30px;
            transition: transform 0.2s ease, box-shadow 0.2s ease;
        }

        .section:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.12);
        }

        .section h2 {
            font-size: 2rem;
            font-weight: 600;
            margin-bottom: 25px;
            color: #2c3e50;
        }

        .news-scroll-container {
            max-height: 300px;
            overflow-y: auto;
            background: #f8f9fa;
            border-radius: 8px;
            padding: 15px;
            border: 1px solid #e9ecef;
        }
        
        .news-list {
            list-style: none;
            margin: 0;
            padding: 0;
        }
        
        .news-list li {
            padding: 15px 20px;
            margin-bottom: 8px;
            background: white;
            border-radius: 8px;
            border-left: 4px solid #6c757d;
            transition: all 0.2s ease;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }
        
        .news-list li:hover {
            transform: translateX(5px);
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.15);
        }
        
        .news-list li:last-child {
            margin-bottom: 0;
        }
        
        .news-list li strong {
            color: #2c3e50;
            font-weight: 600;
        }
        
        .news-list li a {
            color: #495057;
            text-decoration: none;
            font-weight: 500;
        }
        
        .news-list li a:hover {
            color: #2c3e50;
        }

        .research-grid {
            display: grid;
            gap: 25px;
        }

        .research-item {
            display: grid;
            grid-template-columns: 280px 1fr;
            gap: 25px;
            padding: 25px;
            background: white;
            border-radius: 8px;
            border-left: 4px solid #6c757d;
            transition: all 0.2s ease;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .research-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.12);
        }

        .research-item.featured {
            border-left-color: #28a745;
        }

        .research-image {
            overflow: hidden;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .research-image img {
            width: 100%;
            height: 180px;
            object-fit: cover;
            transition: transform 0.3s ease;
        }

        .research-item:hover .research-image img {
            transform: scale(1.02);
        }

        .research-content h3 {
            font-size: 1.3rem;
            font-weight: 600;
            margin-bottom: 12px;
            color: #2c3e50;
        }

        .research-content h3 a {
            text-decoration: none;
            color: inherit;
            transition: color 0.2s ease;
        }

        .research-content h3 a:hover {
            color: #495057;
        }

        .research-content p {
            color: #555;
            margin-bottom: 15px;
        }

        .research-links {
            display: flex;
            flex-wrap: wrap;
            gap: 10px;
            margin: 15px 0;
        }

        .research-links a {
            padding: 6px 12px;
            background: #e9ecef;
            color: #495057;
            text-decoration: none;
            border-radius: 4px;
            font-size: 0.85rem;
            font-weight: 500;
            transition: all 0.2s ease;
        }

        .research-links a:hover {
            background: #6c757d;
            color: white;
        }

        .badge {
            display: inline-block;
            padding: 4px 10px;
            background: #6c757d;
            color: white;
            border-radius: 4px;
            font-size: 0.75rem;
            font-weight: 600;
            margin-left: 8px;
            margin-bottom: 4px;
        }

        .badge.green {
            background: #28a745;
        }

        .badge.blue {
            background: #007bff;
        }

        .badge.purple {
            background: #6f42c1;
        }

        .badge.pink {
            background: #e83e8c;
        }

        .teaching-grid {
            display: grid;
            gap: 20px;
        }

        .teaching-item {
            display: grid;
            grid-template-columns: 200px 1fr;
            gap: 20px;
            padding: 25px;
            background: white;
            border-radius: 8px;
            border-left: 4px solid #6c757d;
            transition: all 0.2s ease;
            box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
        }

        .teaching-item:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.12);
        }

        .teaching-image img {
            width: 100%;
            height: 120px;
            object-fit: cover;
            border-radius: 8px;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }

        .teaching-content h3 {
            font-size: 1.2rem;
            font-weight: 600;
            margin-bottom: 8px;
            color: #2c3e50;
        }

        .teaching-content p {
            color: #555;
            margin-bottom: 8px;
        }

        /* Custom scrollbar styling */
        .news-scroll-container::-webkit-scrollbar {
            width: 6px;
        }
        
        .news-scroll-container::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 3px;
        }
        
        .news-scroll-container::-webkit-scrollbar-thumb {
            background: #6c757d;
            border-radius: 3px;
        }
        
        .news-scroll-container::-webkit-scrollbar-thumb:hover {
            background: #5a6268;
        }

        @keyframes fadeInUp {
            from {
                opacity: 0;
                transform: translateY(20px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .footer {
            text-align: center;
            padding: 20px;
            color: #6c757d;
            font-size: 0.9rem;
        }

        .footer a {
            color: #495057;
            text-decoration: none;
            transition: color 0.2s ease;
        }

        .footer a:hover {
            color: #2c3e50;
        }

        @media (max-width: 768px) {
            .hero-section {
                grid-template-columns: 1fr;
                text-align: center;
                padding: 25px;
            }

            .hero-content h1 {
                font-size: 2.2rem;
            }

            .research-item,
            .teaching-item {
                grid-template-columns: 1fr;
                text-align: center;
            }

            .research-image img {
                height: 150px;
            }

            .hero-links {
                flex-direction: column;
                align-items: center;
            }

            .section {
                padding: 20px;
            }
        }
    </style>
</head>

<body>
    <div class="container">
        <div class="main-card">
            <div class="hero-section">
                <div class="hero-content">
                    <h1>Shaden Alshammari</h1>
                    <p>
                        I'm an incoming PhD student in EECS at 
                        <a href="https://csail.mit.edu/" style="color:#495057; text-decoration: none; font-weight: 500;">MIT CSAIL</a>, co-advised by <a href="https://groups.csail.mit.edu/vision/torralbalab/" style="color:#495057; text-decoration: none; font-weight: 500;">Antonio Torralba</a> and <a href="https://billf.mit.edu/" style="color:#495057; text-decoration: none; font-weight: 500;">William T. Freeman</a>. My research focuses on advancing 
                        self-supervised learning and vision-language models.
                    </p>
                    <p>
                        I completed my B.S. in Mathematics and Computer Science at MIT, where I worked with amazing mentors including 
                        <a href="https://www.ri.cmu.edu/ri-faculty/deva-ramanan/" style="color:#495057; text-decoration: none; font-weight: 500;">Deva Ramanan</a> and 
                        <a href="https://scholar.google.com/citations?user=gDiWvFoAAAAJ" style="color:#495057; text-decoration: none; font-weight: 500;">Shu Kong</a> at 
                        <a href="https://labs.ri.cmu.edu/av-center/" style="color:#495057; text-decoration: none; font-weight: 500;">CMU's Argo AI Center</a>, 
                        as well as <a href="http://www.cs.cmu.edu/~abhinavg/" style="color:#495057; text-decoration: none; font-weight: 500;">Abhinav Gupta</a> and 
                        <a href="https://vdean.github.io" style="color:#495057; text-decoration: none; font-weight: 500;">Victoria Dean</a> at 
                        <a href="https://www.ri.cmu.edu/" style="color:#495057; text-decoration: none; font-weight: 500;">CMU's Robotics Institute</a>.
                    </p>
                    <p>
                        Beyond research, I'm active in the math olympiad community as a former contestant (IMO Bronze 2017, EGMO and BMO Gold 2016). I also train students, design problems, and I served as a deputy leader and observer at IMO and EGMO.
                    </p>
                    <div class="hero-links">
                        <a href="mailto:shaden@mit.edu">Email</a>
                        <a href="data/Shaden_CV_.pdf">CV</a>
                        <a href="https://scholar.google.com/citations?user=2GYNli8AAAAJ&hl=en">Scholar</a>
                        <a href="https://github.com/ShadeAlsha">GitHub</a>
                    </div>
                </div>
                <div class="profile-image">
                    <img src="images/shaden.jpg" alt="Profile photo">
                </div>
            </div>
        </div>

        <div class="section">
            <h2>News</h2>
            <div class="news-scroll-container">
                <ul class="news-list">
                    <li>Excited to join <a href="https://tedai-vienna.ted.com">TEDAI Vienna</a> as a speaker in <strong>September 2025</strong>!</li>
                    <li>Excited to be a speaker at <a href="https://www.mlss-melbourne.com">Machine Learning Summer School MLSS</a> in Melbourne in <strong>February 2026</strong>!</li>
                    <li><strong>July 2025:</strong> Delighted to spend a week teaching at the KAUST AI Summer School.</li>
                    <li><strong>May/June 2025:</strong> Gave a talk on I-Con at Microsoft MAIDAP and Princeton Visual AI Lab.</li>
                    <li><strong>March 2025:</strong> Received the Schwarzman College of Computing Fellowship (MIT EECS).</li>
                    <li><strong>28 February 2025:</strong> Awarded EDGE Doctoral Fellowship (Stanford University).</li>
                    <li><strong>26 February 2025:</strong> NegBench has been accepted to CVPR 2025!</li>
                    <li><strong>17 February 2025:</strong> Awarded the Gordon Wu Fellowship (Princeton University).</li>
                    <li><strong>22 January 2025:</strong> I-Con has been accepted to ICLR 2025!</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <h2>Research</h2>
            <div class="research-grid">
                <div class="research-item featured">
                    <div class="research-image">
                        <img src="images/I-Con2.png" alt="Unifying Framework">
                    </div>
                    <div class="research-content">
                        <h3>
                            <a href="https://aka.ms/i-con">I-Con: A Unifying Framework for Representation Learning</a>
                        </h3>
                        <p><strong>Shaden A.</strong>, John R. Hershey, Axel Feldmann, William T. Freeman, Mark Hamilton</p>
                        <div class="research-links">
                            <a href="https://aka.ms/i-con">Project Website</a>
                            <a href="https://youtu.be/UvjTbnFzRac">Video Explainer</a>
                            <a href="https://arxiv.org/pdf/2504.16929">Paper</a>
                            <a href="https://github.com/ShadeAlsha/ICon">Code</a>
                        </div>
                        <span class="badge">ICLR 2025</span>
                        <span class="badge blue">
                          <a href="https://news.mit.edu/2025/machine-learning-periodic-table-could-fuel-ai-discovery-0423" style="color: white; text-decoration: none;">
                           MIT News
                          </a>
                        </span>
                        <p>A unified framework that generalizes loss functions in representation learning, exposing connections across methods and achieving state-of-the-art results in unsupervised image classification on ImageNet-1K.</p>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-image">
                        <img src="images/VisionLanguageModels.png" alt="Vision Language Models">
                    </div>
                    <div class="research-content">
                        <h3>Vision-Language Models Do Not Understand Negation</h3>
                        <p>Kumail Alhamoud, <strong>Shaden A.</strong>, Yonglong Tian, Guohao Li, Philip Torr, Yoon Kim, Marzyeh Ghassemi</p>
                        <div class="research-links">
                            <a href="http://negbench.github.io">Project Website</a>
                            <a href="https://youtu.be/oOJxwlKUE8M">Video Explainer</a>
                            <a href="https://arxiv.org/pdf/2501.09425">Paper</a>
                            <a href="https://github.com/m1k2zoo/negbench">Code</a>
                        </div>
                        <span class="badge">CVPR 2025</span>
                        <span class="badge blue">
                          <a href="https://news.mit.edu/2025/study-shows-vision-language-models-cant-handle-negation-words-queries-0514" style="color: white; text-decoration: none;">
                            MIT News
                          </a>
                        </span>
                        <p>A benchmark evaluating negation understanding in vision-language models reveals performance limitations, with targeted improvements increasing recall by 10% and accuracy by 40%.</p>
                    </div>
                </div>

                <div class="research-item featured">
                    <div class="research-image">
                        <img src="images/ltr-wb2.png" alt="Long-tailed Recognition">
                    </div>
                    <div class="research-content">
                        <h3>
                            <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Alshammari_Long-Tailed_Recognition_via_Weight_Balancing_CVPR_2022_paper.pdf">Long-tailed Recognition via Weight Balancing</a>
                        </h3>
                        <p><strong>Shaden A.</strong>, Yu-Xiong Wang, Deva Ramanan, Shu Kong</p>
                        <span class="badge">CVPR 2022</span>
                        <span class="badge green">+200 citations!</span>
                        <p>This study explores weight balancing techniques like L2-normalization, weight decay, and MaxNorm to address bias in long-tailed recognition, achieving state-of-the-art results across five benchmarks by balancing classifier weights for rare and common classes.</p>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-image">
                        <img src="images/hearning-touch.png" alt="Contact Microphones">
                    </div>
                    <div class="research-content">
                        <h3>
                            <a href="https://neurips.cc/virtual/2022/57568">Using Contact Microphones for Robot Manipulation</a>
                        </h3>
                        <p><strong>Shaden A.</strong>, Victoria Dean, Tess Hellebrekers, Pedro Morgado, Abhinav Gupta</p>
                        <span class="badge purple">NeurIPS Workshop 2022</span>
                        <p>This work combines visual data with contact audio to enhance manipulation in contact-rich tasks, leveraging high-frequency tactile signals from microphones to outperform single-modality approaches.</p>
                    </div>
                </div>

                <div class="research-item">
                    <div class="research-image">
                        <img src="images/continual-ltr.png" alt="Continual Long-Tailed Recognition">
                    </div>
                    <div class="research-content">
                        <h3>
                            <a href="https://drive.google.com/file/d/1RHc1cEMbl6MdgKOZBa-VM4UG_eHEO9y1/view?usp=sharing">Continual Long-Tailed Recognition: Merge Tail Classes Today, Separate them Tomorrow</a>
                        </h3>
                        <p>Yanan Li, <strong>Shaden A.</strong>, Bin Liu, Shu Kong</p>
                        <span class="badge pink">Preprint 2022</span>
                        <p>This work introduces a continual learning approach for long-tailed recognition, using a Mean-Shift module and Supervised Contrastive loss to improve feature learning and expedite finetuning across time periods, achieving state-of-the-art performance.</p>
                    </div>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>Teaching</h2>
            <div class="teaching-grid">
                <div class="teaching-item">
                    <div class="teaching-image">
                        <img src="images/math.png" alt="MIT Mathematics">
                    </div>
                    <div class="teaching-content">
                        <h3>Lead Graduate Instructor, Linear Algebra and Optimization (18.C06)</h3>
                        <p><a href="https://math.mit.edu/" style="color:#495057; text-decoration: none; font-weight: 500;">MIT Department of Mathematics</a> - Sep 2022 - Jan 2025</p>
                        <p>I teach two weekly recitation sessions to help clarify challenging topics for 38 students and develop weekly handouts and problem sets for a larger group of 180 students. I also coordinate a team of five TAs and three Graders. I was honored to be nominated by my students for the Teaching Awards.</p>
                    </div>
                </div>

                <div class="teaching-item">
                    <div class="teaching-image">
                        <img src="images/kaust-academy.png" alt="AI Summer School">
                    </div>
                    <div class="teaching-content">
                        <h3>Instructor</h3>
                        <p>AI Summer School at KAUST (June, 2025)</p>
                    </div>
                </div>

                <div class="teaching-item">
                    <div class="teaching-image">
                        <img src="images/ml_course.png" alt="MIT EECS">
                    </div>
                    <div class="teaching-content">
                        <h3>Teaching Assistant, Introduction to Machine Learning (6.036)</h3>
                        <p><a href="https://eecs.mit.edu/" style="color:#495057; text-decoration: none; font-weight: 500;">MIT EECS Department</a> - Jan 2024 - May 2024</p>
                        <p>Supported professors in organizing technical materials on ML topics, conducted weekly recitations, lab sessions, and hosted office hours for student learning support.</p>
                    </div>
                </div>

                <div class="teaching-item">
                    <div class="teaching-image">
                        <img src="images/imo.png" alt="Math Olympiad">
                    </div>
                    <div class="teaching-content">
                        <h3>Math Olympiad Trainer</h3>
                        <p>Deputy Leader and Observer @ IMO & EGMO (2019–2023)</p>
                        <p>Trained students in combinatorics, number theory, algebra, and geometry for the International Math Olympiad (IMO), focusing on advanced problem-solving skills. Additionally, contributed by suggesting problems for exams for team selection tests.</p>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <div class="footer">
        <p>Website design credits to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a></p>
    </div>

    <script>
        // Intersection Observer for scroll animations
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -50px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, observerOptions);

        // Observe all sections for scroll animations
        document.querySelectorAll('.section').forEach(section => {
            section.style.opacity = '0';
            section.style.transform = 'translateY(20px)';
            section.style.transition = 'opacity 0.6s ease, transform 0.6s ease';
            observer.observe(section);
        });

        // Smooth scrolling for internal links
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const target = document.querySelector(this.getAttribute('href'));
                if (target) {
                    target.scrollIntoView({
                        behavior: 'smooth',
                        block: 'start'
                    });
                }
            });
        });
    </script>
</body>
</html>
